---
title: "Power Analysis for Final Project"
author: "Cynthia, Emanuel, Jonathan, and Rina "
date: "02/14/2024"
name: "Rina Palta"
output: 
  pdf_document: 
    number_sections: true
---

```{r global options, include = FALSE}
knitr::opts_chunk$set(include = FALSE, message = FALSE, warning = FALSE )

knitr::knit_engines$set(problem_description = function(options) {
  code <- paste(options$code, collapse = "\n")
})
```

```{r package loads, warning=FALSE, message=FALSE}
library(data.table)
library(sandwich)
library(lmtest)

library(ggplot2)
library(knitr)
```

Sleep score ranges from 0-100, with most sleep scores falling in the 60-85 range. Our Yi(0) is a normally distributed variable centered at 72, with a standard error of 3 to reflect this range. Because of our criss-cross design, we're adding the ATE as a normally distributed variable centered at 2 (our projected ATE) with a standard deviation of 1 to each Yi(0). So our Yi(1) = Yi(0) + tau-i


```{r}
d <- data.table()

d[ , condition := rep(c('control', 'treatment'), each = 50)]

control_y <- rnorm(50, mean = 72, sd = 3)

d[condition == 'control', Y := control_y]
d[condition == 'treatment', Y := control_y + rnorm(.N, mean = 2, sd = 1)]

d[ , t.test(Y ~ condition)]
```
```{r}
d
```

Simulating the experiment at different sample sizes, from 10 - 200% of our datatable will give us an idea of what the power of our experiment will be at different sample sizes. 

```{r}

# vector of percentages to sample
percentages_to_sample <- seq(0.10, 2.00, by = 0.10)

# empty vector to store the power calculations at every sample size
power_results <- rep(NA, length(percentages_to_sample))

# number of observations in the original dataset
n_obs <- nrow(d)

# loop through percentages to sample
for (j in seq_along(percentages_to_sample)) {
  # calculate the sample size for each group, control and treatment
  sample_size <- round(percentages_to_sample[j] * n_obs) / 2
  
  # empty vector to store the p-values at the current sample size
  t_test_p_values <- rep(NA, 1000) 
  
  # run the experiment at the current sample size 1000 times and store the 1000 p-values created from each t-test
  for (i in 1:1000) {
    # sample from treatment and control--half in treatment and half in control
    sample_treatment <- d[condition == 'treatment'][sample(.N, sample_size, replace = TRUE)]
    sample_control <- d[condition == 'control'][sample(.N, sample_size, replace = TRUE)]
    
    # combine treatment and control groups
    next_t_test <- rbindlist(list(sample_treatment, sample_control))
    
    # perform t-test
    next_test_result <- next_t_test[ , t.test(Y ~ condition)]
    
    # store the p-value
    t_test_p_values[i] <- next_test_result$p.value
  }
  
  # Calculate power and store in power_results
  power_results[j] <- mean(t_test_p_values <= 0.05)
}


```


```{r}
power_results_table <- data.table()
```

```{r}
#because everyone in the study will be in treatment and control, dividing our number of observations by 2
power_results_table$sample_size <- percentages_to_sample * n_obs / 2
power_results_table$test_power <- power_results

```

```{r}
plot(power_results_table$sample_size, power_results_table$test_power)
```

We reach a power of .8 around 26-27 subjects. 
